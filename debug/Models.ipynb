{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9TqpWSA5xR/CuqTlPO2z0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwhfEiOXDmJo"
      },
      "source": [
        "#Presets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "K-2HSKTcEFh2",
        "outputId": "9deb9f0e-0317-4adc-8f0c-772388efb382"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-82a7c3dd-7f13-440f-9668-54fb1a37580d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-82a7c3dd-7f13-440f-9668-54fb1a37580d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving HAM10000_metadata.csv to HAM10000_metadata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgqvGHc2w85A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8bb523-0395-46d9-8b4b-0ff907864eef"
      },
      "source": [
        "address = 'HAM10000_metadata.csv'\n",
        "df = pd.read_csv(address)\n",
        "df\n",
        "\n",
        "df.info()       #Find general info\n",
        "df.isna().sum() #find how many unknowns\n",
        "df['dx'].value_counts()       #Stratification stats\n",
        "df['dx_type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10015 entries, 0 to 10014\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   lesion_id     10015 non-null  object \n",
            " 1   image_id      10015 non-null  object \n",
            " 2   dx            10015 non-null  object \n",
            " 3   dx_type       10015 non-null  object \n",
            " 4   age           9958 non-null   float64\n",
            " 5   sex           10015 non-null  object \n",
            " 6   localization  10015 non-null  object \n",
            "dtypes: float64(1), object(6)\n",
            "memory usage: 547.8+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "histo        5340\n",
              "follow_up    3704\n",
              "consensus     902\n",
              "confocal       69\n",
              "Name: dx_type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agp0YL9u3Eqi"
      },
      "source": [
        "dx is the diagnosis and type is how the diagnosis was made  https://arxiv.org/abs/1803.10417"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo01nGxS3Q2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89068a95-e21e-4417-a5c8-bd618f731933"
      },
      "source": [
        "dx_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}    #Types of lesion for mapping as words ineffiicent storage\n",
        "\n",
        "df['diagnosis'] = df['dx'].map(dx_dict.get)  #Swap\n",
        "df.sex.value_counts()   #More data points\n",
        "df.localization.value_counts()\n",
        "df.age.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.0    1299\n",
              "50.0    1187\n",
              "55.0    1009\n",
              "40.0     985\n",
              "60.0     803\n",
              "70.0     756\n",
              "35.0     753\n",
              "65.0     731\n",
              "75.0     618\n",
              "30.0     464\n",
              "80.0     404\n",
              "85.0     290\n",
              "25.0     247\n",
              "20.0     169\n",
              "5.0       86\n",
              "15.0      77\n",
              "10.0      41\n",
              "0.0       39\n",
              "Name: age, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VrXZEcm6f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0c79bf-f2a4-4dac-f8f7-7288e03451e7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "value = df.age.mean()\n",
        "print(value)\n",
        "df.age = df.age.fillna(value)\n",
        "df.isna().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51.863828077927295\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lesion_id       0\n",
              "image_id        0\n",
              "dx              0\n",
              "dx_type         0\n",
              "age             0\n",
              "sex             0\n",
              "localization    0\n",
              "diagnosis       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wFsDCnXdwG0"
      },
      "source": [
        "Manually imputed the mean into the age to remove all the Nan from the database while keeping the same mean so the distribution will not change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6-5LeNqeUmk"
      },
      "source": [
        "#**DATA ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAwrleLXeoBc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "UAYZ7hp8e0Q8",
        "outputId": "602a4aaa-5c56-44f8-98b5-f510c47f16f2"
      },
      "source": [
        "df['dx'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5917f79190>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "ME9qAl6nfI1C",
        "outputId": "0040072d-093b-4ea5-f121-c4df8bf09e98"
      },
      "source": [
        "sns.scatterplot('age','dx',data=df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f59176adfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbe57Qg6ftxR"
      },
      "source": [
        "#**Preprocessing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6v7548jDguz"
      },
      "source": [
        "\n",
        "Need to convert words to numbers, need to do it manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmrUaXrnfyFF"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "#Need to label encode and one hot encode/ normalise\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df1 = df.copy()\n",
        "#df1.lesion_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFNyBJao0j-"
      },
      "source": [
        "lesion_id_cat = label_encoder.fit_transform(df1['lesion_id'])\n",
        "lesion_id_cat = pd.DataFrame({'lesion_id_cat': lesion_id_cat})\n",
        "\n",
        "image_id_cat = label_encoder.fit_transform(df1['image_id'])\n",
        "image_id_cat = pd.DataFrame({'image_id_cat': image_id_cat})\n",
        "\n",
        "dx_cat = label_encoder.fit_transform(df1['dx'])\n",
        "dx_cat = pd.DataFrame({'dx_cat': dx_cat})\n",
        "\n",
        "dx_type_cat = label_encoder.fit_transform(df1['dx_type'])\n",
        "dx_type_cat = pd.DataFrame({'dx_type_cat': dx_type_cat})\n",
        "\n",
        "sex_cat = label_encoder.fit_transform(df1['sex'])\n",
        "sex_cat = pd.DataFrame({'sex_cat': sex_cat})\n",
        "\n",
        "localization_cat = label_encoder.fit_transform(df1['localization'])\n",
        "localization_cat = pd.DataFrame({'localization_cat': localization_cat})\n",
        "\n",
        "diagnosis_cat = label_encoder.fit_transform(df1['dx'])\n",
        "diagnosis_cat = pd.DataFrame({'diagnosis_cat': diagnosis_cat})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NH8WYN-3dkDl",
        "outputId": "8a1689ab-a271-4cf9-9c8c-502b4e5a8a70"
      },
      "source": [
        "df1.lesion_id = lesion_id_cat\n",
        "df1.image_id = image_id_cat\n",
        "df1.dx = dx_cat\n",
        "df1.dx_type = dx_type_cat\n",
        "df1.sex = sex_cat\n",
        "df1.localization = localization_cat\n",
        "df1.dx = diagnosis_cat\n",
        "\n",
        "\n",
        "convertor = {\n",
        "    'bkl':2,\n",
        "    'nv':5,\n",
        "    'akiec':0,\n",
        "    'mel':4,\n",
        "    'bcc':1,\n",
        "    'vasc':6,\n",
        "    'df':3,\n",
        "\n",
        "}\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       lesion_id  image_id  dx  dx_type   age  sex  localization  \\\n",
              "0            118      3113   2        3  80.0    1            11   \n",
              "1            118       724   2        3  80.0    1            11   \n",
              "2           2710      2463   2        3  80.0    1            11   \n",
              "3           2710      1355   2        3  80.0    1            11   \n",
              "4           1460      7327   2        3  75.0    1             4   \n",
              "...          ...       ...  ..      ...   ...  ...           ...   \n",
              "10010       2844      8778   0        3  40.0    1             0   \n",
              "10011       2844      9244   0        3  40.0    1             0   \n",
              "10012       2844      9230   0        3  40.0    1             0   \n",
              "10013        239      8548   0        3  80.0    1             5   \n",
              "10014       3487      7952   4        3  70.0    0             2   \n",
              "\n",
              "                            diagnosis  \n",
              "0      Benign keratosis-like lesions   \n",
              "1      Benign keratosis-like lesions   \n",
              "2      Benign keratosis-like lesions   \n",
              "3      Benign keratosis-like lesions   \n",
              "4      Benign keratosis-like lesions   \n",
              "...                               ...  \n",
              "10010               Actinic keratoses  \n",
              "10011               Actinic keratoses  \n",
              "10012               Actinic keratoses  \n",
              "10013               Actinic keratoses  \n",
              "10014                        Melanoma  \n",
              "\n",
              "[10015 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c748130-2084-4c96-8d58-9d3b8a27c6db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>118</td>\n",
              "      <td>3113</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118</td>\n",
              "      <td>724</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2710</td>\n",
              "      <td>2463</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2710</td>\n",
              "      <td>1355</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1460</td>\n",
              "      <td>7327</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10010</th>\n",
              "      <td>2844</td>\n",
              "      <td>8778</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10011</th>\n",
              "      <td>2844</td>\n",
              "      <td>9244</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10012</th>\n",
              "      <td>2844</td>\n",
              "      <td>9230</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10013</th>\n",
              "      <td>239</td>\n",
              "      <td>8548</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10014</th>\n",
              "      <td>3487</td>\n",
              "      <td>7952</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Melanoma</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10015 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c748130-2084-4c96-8d58-9d3b8a27c6db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c748130-2084-4c96-8d58-9d3b8a27c6db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c748130-2084-4c96-8d58-9d3b8a27c6db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jPC025qIAnB",
        "outputId": "ca4deb45-fa59-483e-ead0-ffc30b2ccd8f"
      },
      "source": [
        "print(np.array(df1['dx'])[64])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDlm7IrLfIPQ"
      },
      "source": [
        "#**Normalisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF0VTuqjgMFQ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bJtbFMIfH83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4df6eae-bcc9-43b8-de42-f85ac0e0a3b3"
      },
      "source": [
        "#Using modules\n",
        "\n",
        "scaled_features = df1.copy()\n",
        "\n",
        "col_names = ['lesion_id', 'image_id' , 'dx', 'dx_type', 'age', 'sex', 'localization'] #Removed diagnosis\n",
        "features = scaled_features[col_names]\n",
        "scaler = StandardScaler().fit(features.values)\n",
        "features = scaler.transform(features.values)\n",
        "scaled_features[col_names] =  features\n",
        "\n",
        "X = scaled_features.drop(columns=['dx','lesion_id','image_id'],axis=1)\n",
        "X.insert(0,1.0,1.0)\n",
        "X\n",
        "y = [1 if each == 'bkl' or each == 'nv' or each == 'df' else 0 for each in df.dx] # or y = df.dx\n",
        "\n",
        "print(scaled_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       lesion_id  image_id        dx   dx_type       age       sex  \\\n",
            "0      -1.680017 -0.655118 -1.496108  0.835507  1.662953  0.882321   \n",
            "1      -1.680017 -1.481453 -1.496108  0.835507  1.662953  0.882321   \n",
            "2      -0.474447 -0.879948 -1.496108  0.835507  1.662953  0.882321   \n",
            "3      -0.474447 -1.263195 -1.496108  0.835507  1.662953  0.882321   \n",
            "4      -1.055837  0.802468 -1.496108  0.835507  1.367434  0.882321   \n",
            "...          ...       ...       ...       ...       ...       ...   \n",
            "10010  -0.412122  1.304356 -2.867221  0.835507 -0.701196  0.882321   \n",
            "10011  -0.412122  1.465542 -2.867221  0.835507 -0.701196  0.882321   \n",
            "10012  -0.412122  1.460699 -2.867221  0.835507 -0.701196  0.882321   \n",
            "10013  -1.623738  1.224801 -2.867221  0.835507  1.662953  0.882321   \n",
            "10014  -0.113056  1.018650 -0.124995  0.835507  1.071915 -1.083518   \n",
            "\n",
            "       localization                       diagnosis  \n",
            "0          0.847871  Benign keratosis-like lesions   \n",
            "1          0.847871  Benign keratosis-like lesions   \n",
            "2          0.847871  Benign keratosis-like lesions   \n",
            "3          0.847871  Benign keratosis-like lesions   \n",
            "4         -0.626664  Benign keratosis-like lesions   \n",
            "...             ...                             ...  \n",
            "10010     -1.469256               Actinic keratoses  \n",
            "10011     -1.469256               Actinic keratoses  \n",
            "10012     -1.469256               Actinic keratoses  \n",
            "10013     -0.416016               Actinic keratoses  \n",
            "10014     -1.047960                        Melanoma  \n",
            "\n",
            "[10015 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nysDcpG1gZBD"
      },
      "source": [
        "# Manual\n",
        "\n",
        "#scaled = df1.copy()\n",
        "#Then use maths operations use folder where it is written out\n",
        "#Will experiment with standardisation vs normalisation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0kR3BxZhKsn"
      },
      "source": [
        "#**Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7S9lRMrhG9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9311993b-a038-467a-f442-f5b01ebec2e5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = [1 if each == 'bkl' or each == 'nv' or each == 'df' else 0 for each in df.dx]\n",
        "print(y)\n",
        "print(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "       1.0   dx_type       age       sex  localization  \\\n",
            "0      1.0  0.835507  1.662953  0.882321      0.847871   \n",
            "1      1.0  0.835507  1.662953  0.882321      0.847871   \n",
            "2      1.0  0.835507  1.662953  0.882321      0.847871   \n",
            "3      1.0  0.835507  1.662953  0.882321      0.847871   \n",
            "4      1.0  0.835507  1.367434  0.882321     -0.626664   \n",
            "...    ...       ...       ...       ...           ...   \n",
            "10010  1.0  0.835507 -0.701196  0.882321     -1.469256   \n",
            "10011  1.0  0.835507 -0.701196  0.882321     -1.469256   \n",
            "10012  1.0  0.835507 -0.701196  0.882321     -1.469256   \n",
            "10013  1.0  0.835507  1.662953  0.882321     -0.416016   \n",
            "10014  1.0  0.835507  1.071915 -1.083518     -1.047960   \n",
            "\n",
            "                            diagnosis  \n",
            "0      Benign keratosis-like lesions   \n",
            "1      Benign keratosis-like lesions   \n",
            "2      Benign keratosis-like lesions   \n",
            "3      Benign keratosis-like lesions   \n",
            "4      Benign keratosis-like lesions   \n",
            "...                               ...  \n",
            "10010               Actinic keratoses  \n",
            "10011               Actinic keratoses  \n",
            "10012               Actinic keratoses  \n",
            "10013               Actinic keratoses  \n",
            "10014                        Melanoma  \n",
            "\n",
            "[10015 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e75LIvVRiUad",
        "outputId": "13085f71-e953-46c5-d128-a14d7480d21d"
      },
      "source": [
        "y.count(0) # == 2096\n",
        "y.count(1) # == 7919"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7919"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ10vTIC5oEw",
        "outputId": "efc69df4-16f4-4e43-aee1-d3c2631ed6b2"
      },
      "source": [
        "print(X_train)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      1.0   dx_type       age       sex  localization  \\\n",
            "1074  1.0 -2.092788 -0.405678 -1.083518     -1.469256   \n",
            "3588  1.0 -0.628640 -0.110159 -1.083518      1.479814   \n",
            "8385  1.0  0.835507 -1.883271  0.882321     -1.469256   \n",
            "2205  1.0  0.835507  1.367434  0.882321      1.479814   \n",
            "2441  1.0 -2.092788 -0.996715 -1.083518      1.058519   \n",
            "...   ...       ...       ...       ...           ...   \n",
            "2895  1.0  0.835507 -0.405678  0.882321      1.479814   \n",
            "7813  1.0  0.835507 -2.769827 -1.083518     -0.205369   \n",
            "905   1.0 -2.092788  1.662953 -1.083518     -0.416016   \n",
            "5192  1.0 -0.628640 -0.405678 -1.083518      0.426575   \n",
            "235   1.0  0.835507  1.662953  0.882321      0.847871   \n",
            "\n",
            "                           diagnosis  \n",
            "1074  Benign keratosis-like lesions   \n",
            "3588                Melanocytic nevi  \n",
            "8385                Melanocytic nevi  \n",
            "2205                        Melanoma  \n",
            "2441                Vascular lesions  \n",
            "...                              ...  \n",
            "2895            Basal cell carcinoma  \n",
            "7813                Melanocytic nevi  \n",
            "905   Benign keratosis-like lesions   \n",
            "5192                Melanocytic nevi  \n",
            "235   Benign keratosis-like lesions   \n",
            "\n",
            "[8012 rows x 6 columns]\n",
            "(8012, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S43O6DGojVoR"
      },
      "source": [
        "# Normal equation ==\n",
        "\n",
        "def ComputeCost(X,y,theta):\n",
        "\n",
        "\n",
        "  m = len(y)\n",
        "\n",
        "\n",
        "  predictions = X.dot(theta)\n",
        "\n",
        "  Error = (predictions-y)   #Make sure the right type of squaring should be dot...#\n",
        "\n",
        "  SError = (Error)**2\n",
        "\n",
        "\n",
        "  J = (1/2*m) * sum(SError)\n",
        "  return J\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#ComputeCost(X_train,y_train,theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WPcw7vDu2UE"
      },
      "source": [
        "def Regression(X,y):\n",
        "\n",
        "  theta = np.array([0.79,-0.1,-0.01,-0.14,-0.111]).transpose()\n",
        "  alpha = 0.05\n",
        "  m = len(y)\n",
        "  Js = []\n",
        "\n",
        "  for __ in range(500):\n",
        "\n",
        "    predictions = X_train.dot(theta)-y_train\n",
        "    #print(predictions)\n",
        "    #print(alpha/m)\n",
        "    #print(alpha/m * X_train)\n",
        "\n",
        "    #print(X_train.shape)\n",
        "    #print(predictions.shape)\n",
        "    some = (X_train.transpose().dot(predictions))\n",
        "    #print(some_.shape)\n",
        "\n",
        "    change = ((alpha/m) * some)\n",
        "    #print(change)\n",
        "    theta = theta - change\n",
        "    #print(theta)\n",
        "\n",
        "    J = ComputeCost(X_train,y_train,theta)\n",
        "    Js.append(J)\n",
        "\n",
        "  plt.plot(Js)\n",
        "  print(Js[-1])\n",
        "\n",
        "  return (theta)\n",
        "\n",
        "\n",
        "#25345962.0\n",
        "#25345962.\n",
        "\n",
        "\n",
        "  #Change theta appropriately\n",
        "\n",
        "\n",
        "#print(Regression(X_train,y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4nOPcMJucPk"
      },
      "source": [
        "def Predict(x,y,theta):\n",
        "\n",
        "  values  = round(x.dot(theta))\n",
        "\n",
        "  fp = 0\n",
        "  p  = 0\n",
        "  fn = 0\n",
        "  n  = 0\n",
        "  for a,b in zip(y,values):\n",
        "\n",
        "    if a == 1:\n",
        "      if b == 1:\n",
        "        p += 1\n",
        "      if b == 0:\n",
        "        fp +=1\n",
        "\n",
        "    if a == 0:\n",
        "      if b == 0:\n",
        "        n+=1\n",
        "      if b == 1:\n",
        "        fn += 1\n",
        "\n",
        "  print(p , n)\n",
        "  print(fp , fn)\n",
        "\n",
        "  print(f'Overall acurracy is {(p+n) / (fp+fn+p+n)}')\n",
        "  #Confusion matrix\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pvmG0XNV71qg",
        "outputId": "bee5d8d0-f3cb-4c1e-8c18-5397a85feb19"
      },
      "source": [
        "#Normal Equation\n",
        "print(X_train.T)\n",
        "Xs = ((X_train.T)).dot(X_train)\n",
        "thet = np.linalg.inv(Xs).dot(X_train.transpose())\n",
        "theta  = thet.dot(y_train)\n",
        "\n",
        "print(theta)\n",
        "\n",
        "\n",
        "(ComputeCost(X_train,y_train,theta))\n",
        "\n",
        "print(theta)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        1074              3588  \\\n",
            "1.0                                      1.0               1.0   \n",
            "dx_type                            -2.092788          -0.62864   \n",
            "age                                -0.405678         -0.110159   \n",
            "sex                                -1.083518         -1.083518   \n",
            "localization                       -1.469256          1.479814   \n",
            "diagnosis     Benign keratosis-like lesions   Melanocytic nevi   \n",
            "\n",
            "                          8385      2205              2441              3759  \\\n",
            "1.0                        1.0       1.0               1.0               1.0   \n",
            "dx_type               0.835507  0.835507         -2.092788          -0.62864   \n",
            "age                  -1.883271  1.367434         -0.996715         -0.405678   \n",
            "sex                   0.882321  0.882321         -1.083518         -1.083518   \n",
            "localization         -1.469256  1.479814          1.058519         -0.205369   \n",
            "diagnosis     Melanocytic nevi  Melanoma  Vascular lesions  Melanocytic nevi   \n",
            "\n",
            "                                        115               7822  \\\n",
            "1.0                                      1.0               1.0   \n",
            "dx_type                             0.835507          0.835507   \n",
            "age                                -0.110159         -0.405678   \n",
            "sex                                 0.882321          0.882321   \n",
            "localization                        -1.04796          -1.04796   \n",
            "diagnosis     Benign keratosis-like lesions   Melanocytic nevi   \n",
            "\n",
            "                          8258              6214  ...              3462  \\\n",
            "1.0                        1.0               1.0  ...               1.0   \n",
            "dx_type               0.835507          -0.62864  ...          -0.62864   \n",
            "age                   1.367434         -0.405678  ...         -0.405678   \n",
            "sex                  -1.083518         -1.083518  ...          0.882321   \n",
            "localization          0.426575          -1.04796  ...          1.479814   \n",
            "diagnosis     Melanocytic nevi  Melanocytic nevi  ...  Melanocytic nevi   \n",
            "\n",
            "                          7751              4225  \\\n",
            "1.0                        1.0               1.0   \n",
            "dx_type               0.835507          -0.62864   \n",
            "age                  -0.110159         -0.110159   \n",
            "sex                  -1.083518          0.882321   \n",
            "localization          0.426575         -1.469256   \n",
            "diagnosis     Melanocytic nevi  Melanocytic nevi   \n",
            "\n",
            "                                        144               5056  \\\n",
            "1.0                                      1.0               1.0   \n",
            "dx_type                             0.835507          -0.62864   \n",
            "age                                 1.367434         -0.701196   \n",
            "sex                                 0.882321          0.882321   \n",
            "localization                        -1.04796          -1.04796   \n",
            "diagnosis     Benign keratosis-like lesions   Melanocytic nevi   \n",
            "\n",
            "                              2895              7813  \\\n",
            "1.0                            1.0               1.0   \n",
            "dx_type                   0.835507          0.835507   \n",
            "age                      -0.405678         -2.769827   \n",
            "sex                       0.882321         -1.083518   \n",
            "localization              1.479814         -0.205369   \n",
            "diagnosis     Basal cell carcinoma  Melanocytic nevi   \n",
            "\n",
            "                                        905               5192  \\\n",
            "1.0                                      1.0               1.0   \n",
            "dx_type                            -2.092788          -0.62864   \n",
            "age                                 1.662953         -0.405678   \n",
            "sex                                -1.083518         -1.083518   \n",
            "localization                       -0.416016          0.426575   \n",
            "diagnosis     Benign keratosis-like lesions   Melanocytic nevi   \n",
            "\n",
            "                                        235   \n",
            "1.0                                      1.0  \n",
            "dx_type                             0.835507  \n",
            "age                                 1.662953  \n",
            "sex                                 0.882321  \n",
            "localization                        0.847871  \n",
            "diagnosis     Benign keratosis-like lesions   \n",
            "\n",
            "[6 rows x 8012 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0fa31c200d11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Normal Equation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mthet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtheta\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mthet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matrices are not aligned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matrices are not aligned"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYOqTlYi9GF3"
      },
      "source": [
        "Predict(X_test,y_test,theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf4cSTsnCiZy"
      },
      "source": [
        "Linear regression bad as takes anomolies therefore is not a great idea!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp1_IMmVJtBM"
      },
      "source": [
        "#Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W7ROISpMrgs"
      },
      "source": [
        "def Sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "def SigGrad(z):\n",
        "  return np.multiply(Sigmoid(z),(1-Sigmoid(z)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSlCdPmLMorA"
      },
      "source": [
        "m = X_train.shape[0]\n",
        "\n",
        "Theta1 = np.matrix([[1.1,3.2,3,2,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])  #Needs to be bigger atm only 1 hidden layer\n",
        "Theta2 = np.matrix([[1.1],[2],[1],[1]])\n",
        "print(Theta1.shape)\n",
        "a1 = X_train.copy()\n",
        "\n",
        "def NNCostFunc():#weights, input_layer_size, hidden_layer_size, num_labels, X, y, lamda):\n",
        "  global Theta1, Theta2, a1\n",
        "  #Choosing not to unroll parameters into weight matrices and just use weights\n",
        "\n",
        "  #2 layers, so 2 weight matrices\n",
        "\n",
        "  z2 = Theta1.dot(a1.T)\n",
        "  a2 = Sigmoid(z2)\n",
        "  layer1 = Sigmoid(np.dot(a1,Theta1.transpose()))\n",
        "  #print(layer1)\n",
        "\n",
        "  output = Sigmoid(np.dot(layer1,Theta2))\n",
        "  #print(output.shape)\n",
        "  #print('Cost Is done')\n",
        "\n",
        "\n",
        "\n",
        "  #print(y_train)\n",
        "  Delta3 = (y_train-output.T).T # = (8012,1)\n",
        "  Del21 = (Delta3 * Theta2.T)\n",
        "  #print(Del21.shape)\n",
        "  Del22 = SigGrad(z2)\n",
        "\n",
        "  #add = (np.ones(Del22.shape[1]))\n",
        "  #print(add.shape)\n",
        "  #print(Del22.T.shape)\n",
        "  #Del22 = np.column_stack( (add, Del22.T))\n",
        "\n",
        "  #print(Del22.shape)\n",
        "  #print(Del22) # =2,8013\n",
        "\n",
        "  Delta2 = np.multiply(Del22,Del21.T)\n",
        "\n",
        "  Theta1_grad = (1/m) * (Delta2.dot(a1))\n",
        "  #print(Theta1_grad)\n",
        "\n",
        "  Theta2_grad = (1/m) * (a2.dot(Delta3))\n",
        "  #print(Theta2_grad)\n",
        "\n",
        "  Theta1 += Theta1_grad\n",
        "  Theta2 += Theta2_grad\n",
        "  #print(output)\n",
        "  return Theta1,Theta2,output\n",
        "\n",
        "\n",
        "\n",
        "for _ in range(5000):\n",
        "  Theta1,Theta2,output = NNCostFunc()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhXPrd8FORAC"
      },
      "source": [
        "def predict():\n",
        "\n",
        "  z2 = Theta1.dot(X_test.T)\n",
        "  a2 = Sigmoid(z2)\n",
        "  layer1 = Sigmoid(np.dot(X_test,Theta1.transpose()))\n",
        "  #print(layer1)\n",
        "\n",
        "  output = Sigmoid(np.dot(layer1,Theta2))\n",
        "\n",
        "  success,fail = 0,0\n",
        "  p,n,fp,fn =0,0,0,0\n",
        "  for a,b in zip(y_test,output.tolist()):\n",
        "    b = round(b[0])\n",
        "    if a == b:\n",
        "      success +=1\n",
        "    else:\n",
        "      fail+=1\n",
        "    if a == 1:\n",
        "      if b == 1:\n",
        "        p += 1\n",
        "      if b == 0:\n",
        "        fp +=1\n",
        "\n",
        "    if a == 0:\n",
        "      if b == 0:\n",
        "        n+=1\n",
        "      if b == 1:\n",
        "        fn += 1\n",
        "\n",
        "  print(p , n)\n",
        "  print(fp , fn)\n",
        "    #if b[0] < 0.7:\n",
        "    #  print(a,b)\n",
        "  print( f'Overall Success is {success/(success+fail)} ')\n",
        "predict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqB9zdNLJqS9"
      },
      "source": [
        "#Logistic Regression 1 vs All\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmvuJJDhlugf"
      },
      "source": [
        "We will take a 1 vs many approach, so will need to do a seperate regression for each of the different values for *y*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNehY3BBlYQ4"
      },
      "source": [
        "y = df1['dx']\n",
        "all_theta = np.empty((6,5))\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "      X, y, test_size=0.2, random_state=1)\n",
        "s = y_test+0\n",
        "for x in range(0,6):\n",
        "  y_now = [1 if each==x else 0 for each in y]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      X, y_now, test_size=0.2, random_state=1)\n",
        "    #print(y_now.count(1))\n",
        "\n",
        "  theta = Regression(X_train,y_train)\n",
        "  #print(theta)\n",
        "  all_theta[x] = theta\n",
        "  pred = X_train.dot(theta)\n",
        "\n",
        "print(all_theta)\n",
        "\n",
        "\n",
        "OneVsAllPredict(all_theta,X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZUhviZuyAIN"
      },
      "source": [
        "def OneVsAllPredict(all_theta,X):\n",
        "\n",
        "  #Assume X has 0s\n",
        "  probs = X.dot(all_theta.transpose())\n",
        "  #print(probs)\n",
        "  pred = probs.idxmax(1)\n",
        "  #print(pred)\n",
        "\n",
        "  print(s[70:80])\n",
        "  success = 0\n",
        "  fail = 0\n",
        "  for a,b in zip(s,pred):\n",
        "    if a==b:\n",
        "      success +=1\n",
        "    else:\n",
        "      fail+=1\n",
        "  print(f'Overall Accuracy of {success/(success+fail)}')   #0.6689\n",
        "\n",
        "  s_1var = [1 if each == 2 or each == 5 or each == 3 else 0 for each in s]\n",
        "  pred_1 = [1 if each == 2 or each == 5 or each == 3 else 0 for each in s]\n",
        "\n",
        "  for a,b in zip(s_1var,pred_1):\n",
        "    if a==b:\n",
        "      success +=1\n",
        "    else:\n",
        "      fail+=1\n",
        "  print(f'Overall Accuracy 2 of {success/(success+fail)}')   #0.8344\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "OneVsAllPredict(all_theta,X_test)\n",
        "\n",
        "\n",
        "#Overall still overpredicts on 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llbySpDo769x"
      },
      "source": [
        "# To do\n",
        "\n",
        "Here, we need to do standardisation and normalisation using no modules!\n",
        "If time make a svm but otherwise will be fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTo9gK_0ks5Z"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
