{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramstar3000/SkinDetection/blob/main/debug/CNN_debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDwu1QdM6Uck",
        "outputId": "8ce76df3-5e29-4eda-fc55-c089643d1bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from google.colab import files,output\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from random import randint\n",
        "from cv2 import warpAffine, getRotationMatrix2D, resize\n",
        "\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tn0ZIigprjz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT4Wxt0nlAmm"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "files.upload()\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list\n",
        "\n",
        "import kaggle\n",
        "\n",
        "! kaggle datasets download -d ramstar3000/ham10000\n",
        "! mkdir Images\n",
        "! unzip ham10000.zip -d Images\n",
        "output.clear()\n",
        "\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsdQGCTyyDu3"
      },
      "outputs": [],
      "source": [
        "def rotation(image): # Image array\n",
        "\n",
        "  image = (image.astype(np.uint8)).reshape(28,28,3)\n",
        "\n",
        "  i = randint(0,15)\n",
        "  height, width = image.shape[:2]\n",
        "  center = (28/2, 28/2)\n",
        "  # print(center)\n",
        "  #print(image.shape)\n",
        "  image = warpAffine(src=image, M=getRotationMatrix2D(center=center, angle=i, scale=1) , dsize=(width, height))\n",
        "\n",
        "  newImage = resize(image, (28, 28))\n",
        "\n",
        "  image = (newImage.astype(np.float64)).reshape(2352,)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRzKFTAZfRR4"
      },
      "outputs": [],
      "source": [
        "def stratify_img_matrix():\n",
        "    csv = pd.read_csv('Images/out.csv')   #/content/Images/hmnist_28_28_RGB.csv\n",
        "\n",
        "    _ = np.array(pd.DataFrame(csv))\n",
        "\n",
        "    print(_.shape)\n",
        "\n",
        "    for row in _:\n",
        "      #print(row[-1])\n",
        "      #print(1)\n",
        "      if row[-1] != 4 and row[-1] != 6 and row[-1] != 2:\n",
        "        label = row[-1]\n",
        "        new = rotation(row[:-1])\n",
        "        new = np.append(new,int(label))\n",
        "\n",
        "        #print(new.shape)\n",
        "        assert new[-1] == label\n",
        "\n",
        "        #print(_.shape)\n",
        "        #print(new.shape)\n",
        "\n",
        "        _ = np.vstack([_, new])\n",
        "\n",
        "        #_ = np.append(_,new,axis=0)\n",
        "\n",
        "\n",
        "    print(_.shape)\n",
        "\n",
        "    csv = pd.DataFrame(_)\n",
        "\n",
        "    column_names = list(range(2352))\n",
        "    column_names.append('label')\n",
        "    csv.columns = column_names\n",
        "\n",
        "\n",
        "    from pathlib import Path\n",
        "    filepath = Path('Images/out2.csv')\n",
        "    #filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "    csv.to_csv(filepath, header=False, index=False)\n",
        "\n",
        "\n",
        "#stratify_img_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyeO0S8j6WxQ"
      },
      "outputs": [],
      "source": [
        "def get_img_matrix():\n",
        "\n",
        "    csv = pd.read_csv('Images/out2.csv')   #/content/Images/hmnist_28_28_RGB.csv\n",
        "\n",
        "    #print(csv)\n",
        "    #csv = pd.DataFrame(_)\n",
        "\n",
        "    column_names = list(range(1,2353))\n",
        "    column_names.append('label')\n",
        "    csv.columns = column_names\n",
        "\n",
        "\n",
        "\n",
        "    y = csv['label']\n",
        "\n",
        "    #csv['label'].value_counts().plot(kind='bar')\n",
        "\n",
        "    df = pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    X = csv.drop(columns = ['label'])\n",
        "    X = (np.array(X).reshape(-1,28*28*3)) # 3d as 3 channels, -1 refers to orig of 10005\n",
        "\n",
        "\n",
        "    #Now do rotating nonsesne\n",
        "\n",
        "\n",
        "    return X[:-1],y[:-1]\n",
        "\n",
        "\n",
        "#g = get_img_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7S9lRMrhG9x"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def split(X,y):\n",
        "\n",
        "  return train_test_split(\n",
        "      X, y, test_size=0.2, random_state=2)   #Start with random split, should do stratified?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wDmuXdMA4CT"
      },
      "outputs": [],
      "source": [
        "def nanargmax(arr):\n",
        "    idx = np.nanargmax(arr)\n",
        "    idxs = np.unravel_index(idx, arr.shape) #Get index as multi dimension\n",
        "    return idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkoT33GJ6aFX"
      },
      "outputs": [],
      "source": [
        "def init_filter(shape):\n",
        "    stddev = 1 / np.sqrt(np.prod(shape))   # STDDEV used to give rough scale to values\n",
        "    return np.random.normal(loc=0, scale=stddev, size=shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6s1bQkI2kKsx"
      },
      "outputs": [],
      "source": [
        "def init_weights(shape):\n",
        "    return np.random.normal(size=shape) * 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_-Xm9nmXvBG"
      },
      "outputs": [],
      "source": [
        "def relu(array):\n",
        "    array[array<=0] = 0\n",
        "    return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDzpRu9k-izq"
      },
      "outputs": [],
      "source": [
        "def convolution(image, filt, bias, s=1):\n",
        "\n",
        "    (n_f, n_c_f, f, _) = filt.shape # filter dimensions\n",
        "    n_c, in_dim, _ = image.shape # image dimensions\n",
        "\n",
        "    out_dim = int((in_dim - f)/s)+1 # calculate output dimensions some mad formula ting\n",
        "\n",
        "    # Dimensions of filter must match channels of input image\n",
        "\n",
        "    out = np.zeros((n_f,out_dim,out_dim))   #If 8 filters, 8 dimensions(1) provided\n",
        "\n",
        "    # convolve the filter over every part of the image, adding the bias at each step.\n",
        "    #Need to look over and adjust\n",
        "    for curr_f in range(n_f):\n",
        "        curr_y = out_y = 0\n",
        "        while curr_y + f <= in_dim:\n",
        "            curr_x = out_x = 0\n",
        "            while curr_x + f <= in_dim:\n",
        "                #print(curr_f)\n",
        "                out[curr_f, out_y, out_x] = np.sum(filt[curr_f] * image[:,curr_y:curr_y+f, curr_x:curr_x+f]) + bias[curr_f]\n",
        "                curr_x += s #Slide across\n",
        "                out_x += 1  #Move into next location for output\n",
        "            curr_y += s  #Slide down\n",
        "            out_y += 1   #Move 1\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def convolutionBackward(dconv_prev, conv_in, filt, s): #Analyse\n",
        "\n",
        "    #Backpropagation through a convolutional layer.\n",
        "\n",
        "    (n_f, n_c, f, _) = filt.shape\n",
        "    (_a, orig_dim, _b) = conv_in.shape\n",
        "\n",
        "    #assert _ == _b\n",
        "\n",
        "    ## initialize derivatives\n",
        "    dout = np.zeros(conv_in.shape)\n",
        "    dfilt = np.zeros(filt.shape)\n",
        "    dbias = np.zeros((n_f,1))\n",
        "    for curr_f in range(n_f):\n",
        "        # loop through all filters\n",
        "        curr_y = out_y = 0\n",
        "        while curr_y + f <= orig_dim:\n",
        "            curr_x = out_x = 0\n",
        "            while curr_x + f <= orig_dim:\n",
        "                # loss gradient of filter (used to update the filter)\n",
        "                dfilt[curr_f] += dconv_prev[curr_f, out_y, out_x] * conv_in[:, curr_y:curr_y+f, curr_x:curr_x+f]\n",
        "                # loss gradient of the input to the convolution operation (conv1 in the case of this network)\n",
        "                dout[:, curr_y:curr_y+f, curr_x:curr_x+f] += dconv_prev[curr_f, out_y, out_x] * filt[curr_f]\n",
        "                curr_x += s\n",
        "                out_x += 1\n",
        "            curr_y += s\n",
        "            out_y += 1\n",
        "        # loss gradient of the bias\n",
        "        dbias[curr_f] = np.sum(dconv_prev[curr_f])\n",
        "\n",
        "    return dout, dfilt, dbias\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfGnroi3YiPT"
      },
      "outputs": [],
      "source": [
        "def maxpool(image, f=2, s=2):\n",
        "\n",
        "    #Downsample image using size of f and stride of s\n",
        "\n",
        "    try:\n",
        "      n_c, h_prev, w_prev = image.shape #Get old/current dimensions\n",
        "    except:\n",
        "      h_prev, w_prev = image.shape\n",
        "      n_c = 1\n",
        "\n",
        "    h = ((h_prev - f)/s)+1  #Calculate new dimensions of img\n",
        "    w = ((w_prev - f)/s)+1  #Int been moved so beware int((h_prev - f)/s)+1\n",
        "\n",
        "    #print(image)\n",
        "    #print(image[0, 0:2, 4:6])  #[channel num, x:x+2 , y:y+2], is a 2x2 grid\n",
        "\n",
        "\n",
        "    output = np.zeros((n_c, int(h), int(w)))  #Make empty array to be filled\n",
        "\n",
        "    for i in range(n_c): #Once for each channel\n",
        "        # slide maxpool window over each part of the image and assign the max value at each step to the output\n",
        "        curr_y = out_y = 0     #Initialised\n",
        "        while curr_y + f <= h_prev:\n",
        "            curr_x = out_x = 0\n",
        "            while curr_x + f <= w_prev:  #Only runs till reaches end of line\n",
        "                output[i, out_y, out_x] = np.max(image[i, curr_y:curr_y+f, curr_x:curr_x+f])\n",
        "                curr_x += s  #Slide across\n",
        "                out_x += 1   #Next index in final array\n",
        "            curr_y += s    #Slide down\n",
        "            out_y += 1     #Move into next index downwards\n",
        "\n",
        "    return output\n",
        "\n",
        "def maxpoolBackward(dpool, orig, f, s): #Analyse\n",
        "\n",
        "    #Backpropagation through a maxpooling\n",
        "    # Gradients are passed through the indices of greatest value in the original maxpooling during the forward step.\n",
        "\n",
        "    (n_c, orig_dim, _) = orig.shape\n",
        "    dout = np.zeros(orig.shape)\n",
        "\n",
        "    #print(orig)\n",
        "\n",
        "    for c in range(n_c):   #Once for each channel\n",
        "        curr_y = out_y = 0\n",
        "        while curr_y + f <= orig_dim:\n",
        "            curr_x = out_x = 0\n",
        "            while curr_x + f <= orig_dim:\n",
        "                # obtain index of largest value in input for current window\n",
        "\n",
        "                (a, b) = nanargmax(orig[c, curr_y:curr_y+f, curr_x:curr_x+f])\n",
        "                dout[c, curr_y+a, curr_x+b] = dpool[c, out_y, out_x]\n",
        "\n",
        "                curr_x += s\n",
        "                out_x += 1\n",
        "            curr_y += s\n",
        "            out_y += 1\n",
        "\n",
        "    #print(dout)\n",
        "\n",
        "\n",
        "    return dout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2vlEEAyHNnk"
      },
      "outputs": [],
      "source": [
        "def softmax(X):\n",
        "    out = np.exp(X)\n",
        "    return out/np.sum(out)\n",
        "\n",
        "def categoricalCrossEntropy(probs, label):\n",
        "    return -np.sum(label * np.log(probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SufLi18FKuT"
      },
      "outputs": [],
      "source": [
        "def conv(image, label, params, conv_s, pool_f, pool_s):  #1#1#1# Analyse backward, also may be broken\n",
        "\n",
        "    [f1, f2, w3, w4, b1, b2, b3, b4] = params\n",
        "\n",
        "    ##############     Forward       ###############\n",
        "\n",
        "    conv1 = convolution(image, f1, b1, conv_s) # convolution\n",
        "    conv1 = relu(conv1) # pass through ReLU non-linearity\n",
        "\n",
        "    conv2 = convolution(conv1, f2, b2, conv_s) # second convolution\n",
        "    conv2 = relu(conv2) # pass through ReLU non-linearity\n",
        "    #print(conv2.shape)\n",
        "\n",
        "    pooled = maxpool(conv2, pool_f, pool_s) # maxpooling\n",
        "\n",
        "    (nf2, dim2, _) = pooled.shape\n",
        "    fc = pooled.reshape((nf2 * dim2 * dim2, 1)) # flatten\n",
        "    #print(fc.shape)\n",
        "\n",
        "    z = w3.dot(fc) + b3 # first dense layer\n",
        "    z = relu(z) # pass through ReLU non-linearity\n",
        "\n",
        "    out = w4.dot(z) + b4 # second dense layer\n",
        "\n",
        "    probs = softmax(out) # predict class probabilities with the softmax activation function\n",
        "    #print(probs)\n",
        "\n",
        "    #Calculate Loss (Loss function is for batch, cost for multiple)\n",
        "    loss = categoricalCrossEntropy(probs, label) # categorical cross-entropy loss\n",
        "\n",
        "    #############      Backward      ###############\n",
        "\n",
        "    dout = probs - label # (7,)   derivative of loss w.r.t. final dense layer output\n",
        "    dw4 = dout.dot(z.T) # loss gradient of final dense layer weights\n",
        "    db4 = np.sum(dout, axis = 1).reshape(b4.shape) # loss gradient of final dense layer biases\n",
        "\n",
        "    dz = w4.T.dot(dout) # loss gradient of first dense layer outputs\n",
        "    dz[z<=0] = 0\n",
        "\n",
        "    dw3 = dz.dot(fc.T)\n",
        "    db3 = np.sum(dz, axis = 1).reshape(b3.shape)\n",
        "\n",
        "    dfc = w3.T.dot(dz) # loss gradients of fully-connected layer (pooling layer)\n",
        "    dpool = dfc.reshape(pooled.shape) # reshape fully connected into dimensions of pooling layer\n",
        "\n",
        "    dconv2 = maxpoolBackward(dpool, conv2, pool_f, pool_s) # backprop through the max-pooling layer(only neurons with highest activation in window get updated)\n",
        "    dconv2[conv2<=0] = 0\n",
        "\n",
        "    dconv1, df2, db2 = convolutionBackward(dconv2, conv1, f2, conv_s) # backpropagate previous gradient through second convolutional layer.\n",
        "    dconv1[conv1<=0] = 0\n",
        "\n",
        "    dimage, df1, db1 = convolutionBackward(dconv1, image, f1, conv_s) # backpropagate previous gradient through first convolutional layer.\n",
        "\n",
        "    grads = [df1, df2, dw3, dw4, db1, db2, db3, db4]\n",
        "\n",
        "    return grads, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5qvvWsfF6EX"
      },
      "outputs": [],
      "source": [
        "def adamGD(batch, num_classes, lr, dim, n_c, beta1, beta2, params, cost): #1#1#1# Research\n",
        "\n",
        "    #This is an adaptive descent mode\n",
        "\n",
        "    # update the parameters through Adam gradient descnet.\n",
        "\n",
        "    [f1, f2, w3, w4, b1, b2, b3, b4] = params  #Unroll params\n",
        "\n",
        "    X = batch[:,0:-1] # get inputs\n",
        "    X = X.reshape(len(batch), n_c, dim, dim)   #Get input to right format\n",
        "    Y = batch[:,-1] # get labels\n",
        "\n",
        "    cost_ = 0\n",
        "    batch_size = len(batch)   #Should be 32 (May change)\n",
        "\n",
        "    # initialize gradients and momentum,RMS params\n",
        "    df1 = np.zeros(f1.shape)\n",
        "    df2 = np.zeros(f2.shape)\n",
        "    dw3 = np.zeros(w3.shape)\n",
        "    dw4 = np.zeros(w4.shape)\n",
        "    db1 = np.zeros(b1.shape)\n",
        "    db2 = np.zeros(b2.shape)\n",
        "    db3 = np.zeros(b3.shape)\n",
        "    db4 = np.zeros(b4.shape)\n",
        "\n",
        "    v1 = np.zeros(f1.shape)\n",
        "    v2 = np.zeros(f2.shape)\n",
        "    v3 = np.zeros(w3.shape)\n",
        "    v4 = np.zeros(w4.shape)\n",
        "    bv1 = np.zeros(b1.shape)\n",
        "    bv2 = np.zeros(b2.shape)\n",
        "    bv3 = np.zeros(b3.shape)\n",
        "    bv4 = np.zeros(b4.shape)\n",
        "\n",
        "    s1 = np.zeros(f1.shape)\n",
        "    s2 = np.zeros(f2.shape)\n",
        "    s3 = np.zeros(w3.shape)\n",
        "    s4 = np.zeros(w4.shape)\n",
        "    bs1 = np.zeros(b1.shape)\n",
        "    bs2 = np.zeros(b2.shape)\n",
        "    bs3 = np.zeros(b3.shape)\n",
        "    bs4 = np.zeros(b4.shape)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        x = X[i]\n",
        "        y = np.eye(num_classes)[int(Y[i])].reshape(num_classes, 1) # convert label to one-hot\n",
        "\n",
        "        # Collect Gradients for training example\n",
        "        grads, loss = conv(x, y, params, 1, 2, 2)\n",
        "        [df1_, df2_, dw3_, dw4_, db1_, db2_, db3_, db4_] = grads\n",
        "\n",
        "\n",
        "        #Update the change in values\n",
        "        df1+=df1_\n",
        "        db1+=db1_\n",
        "        df2+=df2_\n",
        "        db2+=db2_\n",
        "        dw3+=dw3_\n",
        "        db3+=db3_\n",
        "        dw4+=dw4_\n",
        "        db4+=db4_\n",
        "\n",
        "        cost_+= loss\n",
        "\n",
        "    # Parameter Update\n",
        "\n",
        "    v1 = beta1*v1 + (1-beta1)*df1/batch_size # momentum update\n",
        "    s1 = beta2*s1 + (1-beta2)*(df1/batch_size)**2 # RMSProp update\n",
        "    f1 -= lr * v1/np.sqrt(s1+1e-7) # combine momentum and RMSProp to perform update with Adam\n",
        "\n",
        "    bv1 = beta1*bv1 + (1-beta1)*db1/batch_size\n",
        "    bs1 = beta2*bs1 + (1-beta2)*(db1/batch_size)**2\n",
        "    b1 -= lr * bv1/np.sqrt(bs1+1e-7)\n",
        "\n",
        "    v2 = beta1*v2 + (1-beta1)*df2/batch_size\n",
        "    s2 = beta2*s2 + (1-beta2)*(df2/batch_size)**2\n",
        "    f2 -= lr * v2/np.sqrt(s2+1e-7)\n",
        "\n",
        "    bv2 = beta1*bv2 + (1-beta1) * db2/batch_size\n",
        "    bs2 = beta2*bs2 + (1-beta2)*(db2/batch_size)**2\n",
        "    b2 -= lr * bv2/np.sqrt(bs2+1e-7)\n",
        "\n",
        "    v3 = beta1*v3 + (1-beta1) * dw3/batch_size\n",
        "    s3 = beta2*s3 + (1-beta2)*(dw3/batch_size)**2\n",
        "    w3 -= lr * v3/np.sqrt(s3+1e-7)\n",
        "\n",
        "    bv3 = beta1*bv3 + (1-beta1) * db3/batch_size\n",
        "    bs3 = beta2*bs3 + (1-beta2)*(db3/batch_size)**2\n",
        "    b3 -= lr * bv3/np.sqrt(bs3+1e-7)\n",
        "\n",
        "    v4 = beta1*v4 + (1-beta1) * dw4/batch_size\n",
        "    s4 = beta2*s4 + (1-beta2)*(dw4/batch_size)**2\n",
        "    w4 -= lr * v4 / np.sqrt(s4+1e-7)\n",
        "\n",
        "    bv4 = beta1*bv4 + (1-beta1)*db4/batch_size\n",
        "    bs4 = beta2*bs4 + (1-beta2)*(db4/batch_size)**2\n",
        "    b4 -= lr * bv4 / np.sqrt(bs4+1e-7)\n",
        "\n",
        "\n",
        "    cost_ = cost_/batch_size  # Divide down as overall cost\n",
        "    cost.append(cost_)        # Put onto big list\n",
        "\n",
        "    params = [f1, f2, w3, w4, b1, b2, b3, b4]  #Roll into 1 list\n",
        "\n",
        "    return params, cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8BxwX2QF7QK",
        "outputId": "b48fea72-30ce-4433-9978-eb23399f1b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[192. 138. 153. ... 136. 104. 117.]\n",
            " [ 38.  19.  30. ...  25.  12.  15.]\n",
            " [158. 113. 139. ... 109.  78.  92.]\n",
            " ...\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]] 0        2.0\n",
            "1        2.0\n",
            "2        2.0\n",
            "3        2.0\n",
            "4        2.0\n",
            "        ... \n",
            "11875    1.0\n",
            "11876    1.0\n",
            "11877    1.0\n",
            "11878    1.0\n",
            "11879    1.0\n",
            "Name: label, Length: 11880, dtype: float64\n",
            "[[192. 138. 153. ... 136. 104. 117.]\n",
            " [ 38.  19.  30. ...  25.  12.  15.]\n",
            " [158. 113. 139. ... 109.  78.  92.]\n",
            " ...\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]] 0        2.0\n",
            "1        2.0\n",
            "2        2.0\n",
            "3        2.0\n",
            "4        2.0\n",
            "        ... \n",
            "11875    1.0\n",
            "11876    1.0\n",
            "11877    1.0\n",
            "11878    1.0\n",
            "11879    1.0\n",
            "Name: label, Length: 11880, dtype: float64\n",
            "Learning Rate:0.0125, Batch Size:16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cost: 2.216: 100%|██████████| 594/594 [40:49<00:00,  4.12s/it]\n",
            "Cost: 1.353: 100%|██████████| 594/594 [40:43<00:00,  4.11s/it]\n",
            "Cost: 1.085: 100%|██████████| 594/594 [40:41<00:00,  4.11s/it]\n",
            "Cost: 1.377: 100%|██████████| 594/594 [40:40<00:00,  4.11s/it]\n"
          ]
        }
      ],
      "source": [
        "def train(num_classes = 7, lr = 0.0125, beta1 = 0.95, beta2 = 0.99, img_dim = 28, img_channels = 3, f = 5, num_filt1 = 8, num_filt2 = 8, batch_size = 16, num_epochs = 4):\n",
        "\n",
        "    # get data\n",
        "\n",
        "    X,y = get_img_matrix()\n",
        "    #print(X,y)\n",
        "\n",
        "    X = np.array(X,dtype=float)\n",
        "\n",
        "\n",
        "    #print(X,y)\n",
        "\n",
        "    X-= int(np.mean(X))\n",
        "    X/= int(np.std(X))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = split(X,np.array(y))\n",
        "\n",
        "    train_data = np.hstack((X_train,y_train.reshape(-1,1)))\n",
        "\n",
        "    np.random.shuffle(train_data)\n",
        "\n",
        "\n",
        "    #f is size of the window that is scanned, so in this case 5x5 window\n",
        "    #Each layer can have a varying number of filters so far is 8, change google says 32\n",
        "    #3 image channels as red green and blue, have data for 1 but oh well\n",
        "    #For the weights, the 128 can be changed but output layer must have 7 and input 800 from the pooling\n",
        "\n",
        "    ##################################################\n",
        "    ####### Initializing all the parameters ##########\n",
        "    ##################################################\n",
        "\n",
        "\n",
        "    #Initialise the filters and weights\n",
        "    f1, f2 =  init_filter((num_filt1 ,img_channels,f,f)), init_filter((num_filt2 ,num_filt1,f,f))\n",
        "    w3, w4 = init_filter((128,800)), init_filter((7, 128))\n",
        "\n",
        "\n",
        "\n",
        "    #Initialise the bias terms for each stage\n",
        "    b1 = np.zeros((f1.shape[0],1))\n",
        "    b2 = np.zeros((f2.shape[0],1))\n",
        "    b3 = np.zeros((w3.shape[0],1))\n",
        "    b4 = np.zeros((w4.shape[0],1))\n",
        "\n",
        "    params = [f1, f2, w3, w4, b1, b2, b3, b4] #Roll\n",
        "\n",
        "    cost = [] # type: List[float]\n",
        "\n",
        "    #LR = learning rate, can be increased at risk\n",
        "    #Batch size is number of items taken every time\n",
        "\n",
        "    print(\"Learning Rate:\"+str(lr)+\", Batch Size:\"+str(batch_size))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        np.random.shuffle(train_data)\n",
        "        batches = [train_data[k:k + batch_size] for k in range(0, train_data.shape[0], batch_size)]\n",
        "\n",
        "        load_bar = tqdm(batches)\n",
        "        load_bar.set_description(\"Cost: 4\" )  # Cost is appended to array each time\n",
        "\n",
        "        for _,batch in enumerate(load_bar):\n",
        "            params, cost = adamGD(batch, num_classes, lr, img_dim, img_channels, beta1, beta2, params, cost)\n",
        "            load_bar.set_description(f\"Cost: {(cost[-1]) :.3f}\" )\n",
        "\n",
        "    return cost,params\n",
        "cost,params = train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDRomEkRKDzi"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump(params, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbY1qH47C4Za"
      },
      "outputs": [],
      "source": [
        "def predict(image, f1, f2, w3, w4, b1, b2, b3, b4, conv_s=1, pool_f = 2, pool_s = 2):\n",
        "\n",
        "  #Run an image through the CNN using the parameters\n",
        "\n",
        "  conv1 = convolution(image, f1, b1)\n",
        "  conv1 = relu(conv1)               # Relu check\n",
        "\n",
        "  conv2 = convolution(conv1, f2, b2)\n",
        "  conv2 = relu(conv2)\n",
        "\n",
        "  pooled = maxpool(conv2)\n",
        "  (nf2, dim2, _) = pooled.shape\n",
        "  fc = pooled.reshape((nf2 * dim2 * dim2, 1))  # Flattened\n",
        "\n",
        "  # Now do predicting with ANN\n",
        "\n",
        "  z = w3.dot(fc) + b3 # first dense layer\n",
        "  z = relu(z) # [z<=0] = 0 # pass through ReLU non-linearity\n",
        "\n",
        "  out = w4.dot(z) + b4 # second dense layer\n",
        "  probs = softmax(out) # predict class probabilities with the softmax activation function\n",
        "  #print(np.argmax(probs))\n",
        "  return np.argmax(probs), np.max(probs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gdM6JArAagVM",
        "outputId": "ddad5c47-8c30-46fa-d1cd-4a70adf6d574"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(cost,'r') # Plot the cost over each iteration, maybe consider moving average\n",
        "plt.xlabel = 'No. Iterations'\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "Q7n_rOcYbwWr",
        "outputId": "bfd264ef-14d3-4e8e-9618-a4b4ca751efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True  True  True ...  True  True  True]\n",
            "[1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
            "[2. 0. 2. ... 3. 2. 1.]\n",
            "Computing accuracy over test set:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2376/2376 [05:32<00:00,  7.14it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "[f1, f2, w3, w4, b1, b2, b3, b4] = params       # Unload parameters\n",
        "\n",
        "# get data again, duplicated\n",
        "X,y = get_img_matrix()\n",
        "X = np.array(X,dtype=float)  # Needs to be float to do division\n",
        "\n",
        "X-= int(np.mean(X))   #Making into normal, close to 0\n",
        "X/= int(np.std(X))\n",
        "\n",
        "X_train, X_test, y_train, y_test = split(X,np.array(y))\n",
        "test_data = np.hstack((X_test,y_test.reshape(-1,1)))  #combined\n",
        "\n",
        "X = test_data[:,0:-1]\n",
        "X = X.reshape(-1, 3, 28, 28)    #Fit into correct format for filters\n",
        "\n",
        "y = test_data[:,-1]             #Unflip\n",
        "print(y==y_test)\n",
        "ys = [1 if each == 2 or each == 4 or each == 3 else 0 for each in y]\n",
        "print(ys)\n",
        "print(y)\n",
        "corr = 0\n",
        "count = [0 for i in range(7)]\n",
        "correct = [0 for i in range(7)]\n",
        "s,f = 0,0\n",
        "#print()\n",
        "print(\"Computing accuracy over test set:\")\n",
        "\n",
        "t = tqdm(range(len(X)), leave=True)\n",
        "#t = range(len(X))\n",
        "for i in t:\n",
        "    x = X[i]\n",
        "    pred, prob = predict(x, f1, f2, w3, w4, b1, b2, b3, b4)\n",
        "    #print(pred,y[i])\n",
        "    if (pred==2 or pred==5 or pred==3) and (ys[i]==2 or ys[i]==5 or ys[i]==3):\n",
        "      s +=1\n",
        "    else:\n",
        "      if  (not (pred==2 or pred==5 or pred==3)) and (not (ys[i]==2 or ys[i]==5 or ys[i]==3)):\n",
        "        s +=1\n",
        "\n",
        "    count[int(y[i])]+=1\n",
        "    if pred==y[i]:\n",
        "        corr+=1\n",
        "        correct[pred]+=1\n",
        "\n",
        "\n",
        "\n",
        "#print(\"Overall Accuracy: %.3f\" % (float(corr/len(test_data)*100)))\n",
        "#print(\"Overall Accuracy 2: %.3f\" % (float(s/len(test_data)*100)))\n",
        "x = np.arange(7)\n",
        "recall = [x/y for x,y in zip(correct, count)]\n",
        "plt.xlabel = 'Classes'\n",
        "plt.ylabel = 'Recall'\n",
        "plt.title = \"Recall on Test Set\"\n",
        "plt.bar(x,recall)\n",
        "plt.show()\n",
        "\n",
        "#Need to split 7 cats into 2....\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTxjipWr6p2e",
        "outputId": "ebba2528-37fd-44e5-86fc-cf6e6d1c8ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 53.535\n",
            "Overall Accuracy 2: 77.525\n"
          ]
        }
      ],
      "source": [
        "print(\"Overall Accuracy: %.3f\" % (float(corr/len(test_data)*100)))\n",
        "print(\"Overall Accuracy 2: %.3f\" % (float(s/len(test_data)*100)))\n",
        "\n",
        "[f1, f2, w3, w4, b1, b2, b3, b4] = params\n",
        "\n",
        "#print(repr(params[0]))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atvgAvAaNMUQ"
      },
      "outputs": [],
      "source": [
        "with open('objs.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
        "    params2 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht4yp2IBNVXg"
      },
      "outputs": [],
      "source": [
        "print(len(params2))\n",
        "print(len(params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfPRTqSHw4v6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Images/out2.csv')\n",
        "\n",
        "column_names = list(range(1,2353))\n",
        "column_names.append('label')\n",
        "df.columns = column_names\n",
        "\n",
        "print(df['label'][0:10])\n",
        "\n",
        "X = df.drop(['label'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X1 = np.array(X, dtype='uint8')\n",
        "print(X1[0].shape)\n",
        "image = X1[0].reshape(28,28,3)\n",
        "\n",
        "print(image)\n",
        "print(image.shape)\n",
        "#print(X1[0])\n",
        "#print(type(image[0][0][0]))\n",
        "print('=====================================')\n",
        "new_image = np.array(rotation(image),dtype='uint8').reshape(28,28,3)\n",
        "#print(';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;')\n",
        "\n",
        "plt.imshow(new_image)\n",
        "plt.savefig('out.png', bbox_inches='tight', pad_inches=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOyvyv1TyPo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f05b56-4e3a-481d-ebc9-263ce00c2680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 2 17]\n",
            "  [45 78]]\n",
            "\n",
            " [[88 92]\n",
            "  [60 76]]\n",
            "\n",
            " [[76 33]\n",
            "  [20 18]]]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[78.]],\n",
              "\n",
              "       [[92.]],\n",
              "\n",
              "       [[76.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#x = (np.array([[3,1,7,2],[5,1,0,9],[8,2,4,9],[4,3,1,1]]))\n",
        "#x = np.zeros((2,3,4))\n",
        "test_data = np.array([[[2,17], [45, 78]], [[88, 92], [60, 76]],[[76,33],[20,18]]])\n",
        "print(test_data)\n",
        "print('')\n",
        "maxpool(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1Nq3oS3RU2Y"
      },
      "outputs": [],
      "source": [
        "from typing import KeysView\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "    def Load():\n",
        "        driver = self.driver\n",
        "        driver.get(\"https://localhost:5000/\")\n",
        "        driver.able('JS',False)\n",
        "        Keys.send_keys(Keys.RETURN)\n",
        "        return(driver)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLjquGvXRVJu"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump(params, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/pVMFkIqn4fewFDwX8kQx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}